{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae66b68",
   "metadata": {},
   "source": [
    "  \n",
    "Team Members :\n",
    "\n",
    "Aqdas Hussain whu947 \n",
    "\n",
    "Alisha Momin \n",
    "\n",
    "Anbumani Dhanapal - mot356 \n",
    "\n",
    "Sreeja Yalamaddi \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1247413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7581e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Reddit_Comments_Data.csv')\n",
    "\n",
    "# Text preprocessing function to clean the text data\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs, special characters, and digits\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only alphabets and spaces\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing to all comments\n",
    "df['processed_comment'] = df['Comment'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb77595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_len'] = df['processed_comment'].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13c6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech-related lexicon\n",
    "tech_lexicon = [\n",
    "    \"python\", \"html\", \"css\", \"java\", \"javascript\", \"ai\", \"artificial intelligence\", \"internet\",\"machine learning\", \"deep learning\", \"cloud\", \"iot\",\n",
    "    \"raspberry pi\", \"arduino\", \"robotics\", \"blockchain\", \"internet of things\", \"technology\", \"software\", \"hardware\", \"programming\",\n",
    "    \"coding\", \"app\", \"application\", \"android\", \"iphone\", \"linux\", \"github\", \"developer\", \"open source\", \"website\", \"cloud computing\",\n",
    "    \"api\", \"devops\", \"big data\", \"database\", \"data science\", \"cloud storage\", \"virtualization\", \"datacenter\", \"server\", \"network\",\n",
    "    \"fiber\", \"microsoft\", \"apple\", \"amazon\", \"uber\", \"lyft\", \"grubhub\", \"ubereats\", \"doordash\", \"instacart\", \"walmart\", \"ebay\",\n",
    "    \"shopify\", \"airbnb\", \"zoom\", \"slack\", \"docker\", \"kubernetes\", \"dev\", \"scripting\", \"automation\", \"tech startup\", \"gadget\", \"smartphone\",\n",
    "    \"iot device\", \"raspberry pi\", \"software engineer\", \"developer tools\", \"sdk\", \"cyber security\", \"data\", \"analytics\", \"big data\",\n",
    "    \"tcp/ip\", \"udp\", \"ftp\", \"dns\", \"ssl\", \"tls\", \"ip address\", \"ipv4\", \"ipv6\", \"ssh\", \"snmp\", \"bgp\", \"dhcp\", \"nat\",\n",
    "    \"lan\", \"wan\", \"router\", \"switch\", \"hub\", \"gateway\", \"firewall\", \"load balancer\", \"vpn\", \"proxy server\", \"access point\", \"wifi\",\n",
    "    \"bluetooth\", \"4g\", \"5g\", \"ethernet\", \"broadband\", \"fiber optic\", \"lte\", \"mobile hotspot\", \"data plan\", \"bandwidth\", \"latency\",\n",
    "    \"ping\", \"cloud services\", \"aws\", \"google cloud\", \"azure\", \"cloud storage\", \"google drive\", \"dropbox\", \"icloud\", \"cloud computing\",\n",
    "    \"edge computing\", \"cdn\", \"firewall\", \"encryption\", \"cybersecurity\", \"malware\", \"phishing\", \"ddos\", \"data breach\", \"two-factor authentication\",\n",
    "    \"ssl certificate\", \"cyberattack\", \"hacking\", \"intrusion detection\", \"packet sniffing\", \"security protocol\", \"ISP\", \"fiber optic internet\",\n",
    "    \"internet speed\", \"bandwidth throttling\", \"network throughput\", \"routing\", \"switching\", \"network topology\", \"vlan\", \"subnet\", \"dns resolution\",\n",
    "    \"traceroute\", \"throughput\", \"bandwidth usage\", \"network monitoring\", \"speed test\", \"packet loss\", \"debugging\", \"error logs\", \"network diagnostics\",\n",
    "    \"ecommerce\", \"marketplace\", \"shopping cart\", \"payment gateway\", \"online\", \"web apps\", \"mobile apps\", \"qr code\", \"digital wallet\",\n",
    "    \"streaming\", \"bandwidth usage\", \"hd\", \"uhd\", \"4k\", \"netflix\",\"rackspace\", \"geekdom\",\"youtube\", \"hulu\", \"twitch\", \"buffering\", \"video quality\", \"audio streaming\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b69669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech in Education Lexicon\n",
    "tech_education_lexicon = [\n",
    "    \"edtech\", \"elearning\", \"virtual classroom\", \"digital classroom\",\"comptia\", \"online test\",\"technology program\",\n",
    "    \"learning management system\", \"lms\", \"learning analytics\", \"mooc\", \"online class\",\"assistive technology\",\n",
    "    \"gamification\", \"personalized learning\", \"stem education\", \"computer programming\",\"information technology\", \"cs\",\n",
    "    \"interactive whiteboard\", \"google classroom\", \"canvas lms\", \"game design\", \"zoom\",\n",
    "    \"moodle\", \"blackboard\", \"edmodo\", \"kahoot\", \"quizlet\", \"duolingo\", \"coursera\", \"udemy\", \n",
    "    \"edx\", \"skillshare\", \"microsoft teams\", \"slack\", \"google meet\",\"language apps\",\n",
    "    \"microsoft onenote\", \"trello\", \"socrative\", \"ai tutors\",\"online program\", \"computer science\",\n",
    "     \"automated grading systems\", \"codeorg\", \"blockly\",\"stem\", \"khan academy\", \"codecademy\", \"weebly\", \"padlet\", \"evernote\", \"prezi\", \"trello\", \"evernote\", \"cybersecurity\"\n",
    "    \"interactive textbooks\", \"learning apps\", \"etextbooks\", \"digital assessment tools\", \"online exams\",\n",
    "    \"digital portfolios\", \"coding bootcamps\", \"online tutoring\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8409cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech in Education Lexicon\n",
    "tech_workforce_lexicon = [\n",
    "    \"workforce development\", \"skills training\", \"job training\", \"coding bootcamps\", \"technical training\", \"ia jobs\",\n",
    "    \"upskilling\", \"reskilling\", \"career development\", \"career pathways\", \"jobcorps\", \"on the job training\",\n",
    "    \"linkedin\",\"angellist\",\"indeed\",\"glassdoor\",\"angelco\",\"comptia\",\"hire\",\"promote\",\"interview\",\"openings\",\n",
    "    \"digital jobs\", \"cloud computing\", \"programming jobs\", \"it jobs\", \"geekdom\",\"techport\",\"startup week\",\"remote\",\n",
    "    \"cybersecurity jobs\", \"data science\", \"data analyst\", \"ai jobs\", \"machine learning jobs\", \"dice\",\n",
    "    \"cloud certifications\", \"coding for jobs\", \"digital literacy\", \"technology skills\",\"geeksquad\",\n",
    "    \"career growth\", \"employee training\", \"job search platforms\", \"talent development\", \"new technology\",\n",
    "     \"digital transformation\", \"it certification\", \"freelancing platforms\", \"remote work opportunities\", \"job development\", \n",
    "    \"vocational training\", \"digital economy\", \"resume building\", \"linkedin learning\", \"ccna\",\n",
    "    \"skills development\", \"vocational certifications\",  \"job training programs\", \n",
    "    \"learning platforms\", \"technology-enabled careers\", \"coding platforms\", \"skillshare\", \"udacity\", \n",
    "    \"certified it professionals\", \"technology bootcamps\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9157772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " label: Technology\n",
      "  accuracy:    0.8240\n",
      "  macro_precision:   0.8032\n",
      "  macro_recall:   0.7875\n",
      "  micro_precision:   0.8240\n",
      "  micro_recall:   0.8240\n",
      "  Macro F1:    0.7943\n",
      "  Micro F1:    0.8240\n",
      " label: Technology in Education\n",
      "  accuracy:    0.9780\n",
      "  macro_precision:   0.7007\n",
      "  macro_recall:   0.6214\n",
      "  micro_precision:   0.9780\n",
      "  micro_recall:   0.9780\n",
      "  Macro F1:    0.6507\n",
      "  Micro F1:    0.9780\n",
      " label: Technology in Workforce Development\n",
      "  accuracy:    0.9710\n",
      "  macro_precision:   0.7573\n",
      "  macro_recall:   0.8289\n",
      "  micro_precision:   0.9710\n",
      "  micro_recall:   0.9710\n",
      "  Macro F1:    0.7883\n",
      "  Micro F1:    0.9710\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to count lexicon terms in text\n",
    "def count_terms(comment, lexicon):\n",
    "    words = comment.split()\n",
    "    return sum(1 for word in words if word in lexicon)\n",
    "\n",
    "# Apply lexicon-based classification\n",
    "df['tech_count'] = df['processed_comment'].apply(lambda x: count_terms(x, tech_lexicon))\n",
    "df['tech_education_count'] = df['processed_comment'].apply(lambda x: count_terms(x, tech_education_lexicon))\n",
    "df['tech_workforce_count'] = df['processed_comment'].apply(lambda x: count_terms(x, tech_workforce_lexicon))\n",
    "\n",
    "# Generate binary labels for lexicon-based detection\n",
    "df['tech_predicted'] = (df['tech_count'] > 0).astype(int)\n",
    "df['tech_education_predicted'] = (df['tech_education_count'] > 0).astype(int)\n",
    "df['tech_workforce_predicted'] = (df['tech_workforce_count'] > 0).astype(int)\n",
    "\n",
    "# Evaluate lexicon-based predictions\n",
    "def evaluate_predictions(predicted, actual):\n",
    "    accuracy = accuracy_score(actual, predicted)\n",
    "    macro_precision = precision_score(actual, predicted, average='macro')\n",
    "    macro_recall = recall_score(actual, predicted, average='macro') \n",
    "    micro_precision = precision_score(actual, predicted, average='micro')\n",
    "    micro_recall = recall_score(actual, predicted, average='micro') \n",
    "    # Compute Macro and Micro F1 scores\n",
    "    macro_f1 = f1_score(actual, predicted, average='macro')\n",
    "    micro_f1 = f1_score(actual, predicted, average='micro')\n",
    "    return accuracy, macro_precision, macro_recall, micro_precision,micro_recall,macro_f1, micro_f1\n",
    "\n",
    "# Evaluate for each label\n",
    "labels = ['Technology', 'Technology in Education', 'Technology in Workforce Development']\n",
    "predicted_labels = ['tech_predicted', 'tech_education_predicted', 'tech_workforce_predicted']\n",
    "\n",
    "for label, predicted in zip(labels, predicted_labels):\n",
    "    print(f\" label: {label}\")\n",
    "    accuracy, macro_precision, macro_recall, micro_precision,micro_recall,macro_f1, micro_f1 = evaluate_predictions(df[predicted],df[label])\n",
    "    print(f\"  accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"  macro_precision:   {macro_precision:.4f}\")\n",
    "    print(f\"  macro_recall:   {macro_recall:.4f}\")\n",
    "    print(f\"  micro_precision:   {micro_precision:.4f}\")\n",
    "    print(f\"  micro_recall:   {micro_recall:.4f}\")\n",
    "    print(f\"  Macro F1:    {macro_f1:.4f}\")\n",
    "    print(f\"  Micro F1:    {micro_f1:.4f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f0f859",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n",
      "\n",
      "Logistic Regression for Technology Classification Metrics:\n",
      "  accuracy:    0.7450\n",
      "  macro_precision:   0.7553\n",
      "  macro_recall:   0.6316\n",
      "  micro_precision:   0.7450\n",
      "  micro_recall:   0.7450\n",
      "  Macro F1:    0.6373\n",
      "  Micro F1:    0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yalam\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\yalam\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for Technology in Education Classification Metrics:\n",
      "  accuracy:    0.9800\n",
      "  macro_precision:   0.4900\n",
      "  macro_recall:   0.5000\n",
      "  micro_precision:   0.9800\n",
      "  micro_recall:   0.9800\n",
      "  Macro F1:    0.4949\n",
      "  Micro F1:    0.9800\n",
      "Logistic Regression for Technology in Workforce Development Classification Metrics:\n",
      "  accuracy:    0.9700\n",
      "  macro_precision:   0.4850\n",
      "  macro_recall:   0.5000\n",
      "  micro_precision:   0.9700\n",
      "  micro_recall:   0.9700\n",
      "  Macro F1:    0.4924\n",
      "  Micro F1:    0.9700\n",
      "\n",
      "\n",
      "Evaluating Support Vector Machine...\n",
      "\n",
      "Support Vector Machine for Technology Classification Metrics:\n",
      "  accuracy:    0.7400\n",
      "  macro_precision:   0.7151\n",
      "  macro_recall:   0.6479\n",
      "  micro_precision:   0.7400\n",
      "  micro_recall:   0.7400\n",
      "  Macro F1:    0.6578\n",
      "  Micro F1:    0.7400\n",
      "Support Vector Machine for Technology in Education Classification Metrics:\n",
      "  accuracy:    0.9800\n",
      "  macro_precision:   0.7424\n",
      "  macro_recall:   0.6224\n",
      "  micro_precision:   0.9800\n",
      "  micro_recall:   0.9800\n",
      "  Macro F1:    0.6616\n",
      "  Micro F1:    0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yalam\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine for Technology in Workforce Development Classification Metrics:\n",
      "  accuracy:    0.9700\n",
      "  macro_precision:   0.4850\n",
      "  macro_recall:   0.5000\n",
      "  micro_precision:   0.9700\n",
      "  micro_recall:   0.9700\n",
      "  Macro F1:    0.4924\n",
      "  Micro F1:    0.9700\n",
      "\n",
      "\n",
      "Evaluating Random Forest...\n",
      "\n",
      "Random Forest for Technology Classification Metrics:\n",
      "  accuracy:    0.7500\n",
      "  macro_precision:   0.7251\n",
      "  macro_recall:   0.6672\n",
      "  micro_precision:   0.7500\n",
      "  micro_recall:   0.7500\n",
      "  Macro F1:    0.6791\n",
      "  Micro F1:    0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yalam\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest for Technology in Education Classification Metrics:\n",
      "  accuracy:    0.9800\n",
      "  macro_precision:   0.4900\n",
      "  macro_recall:   0.5000\n",
      "  micro_precision:   0.9800\n",
      "  micro_recall:   0.9800\n",
      "  Macro F1:    0.4949\n",
      "  Micro F1:    0.9800\n",
      "Random Forest for Technology in Workforce Development Classification Metrics:\n",
      "  accuracy:    0.9750\n",
      "  macro_precision:   0.9874\n",
      "  macro_recall:   0.5833\n",
      "  micro_precision:   0.9750\n",
      "  micro_recall:   0.9750\n",
      "  Macro F1:    0.6365\n",
      "  Micro F1:    0.9750\n",
      "\n",
      "\n",
      "Evaluating XGBoost...\n",
      "\n",
      "XGBoost for Technology Classification Metrics:\n",
      "  accuracy:    0.7600\n",
      "  macro_precision:   0.7308\n",
      "  macro_recall:   0.6946\n",
      "  micro_precision:   0.7600\n",
      "  micro_recall:   0.7600\n",
      "  Macro F1:    0.7056\n",
      "  Micro F1:    0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yalam\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost for Technology in Education Classification Metrics:\n",
      "  accuracy:    0.9800\n",
      "  macro_precision:   0.4900\n",
      "  macro_recall:   0.5000\n",
      "  micro_precision:   0.9800\n",
      "  micro_recall:   0.9800\n",
      "  Macro F1:    0.4949\n",
      "  Micro F1:    0.9800\n",
      "XGBoost for Technology in Workforce Development Classification Metrics:\n",
      "  accuracy:    0.9700\n",
      "  macro_precision:   0.4850\n",
      "  macro_recall:   0.5000\n",
      "  micro_precision:   0.9700\n",
      "  micro_recall:   0.9700\n",
      "  Macro F1:    0.4924\n",
      "  Micro F1:    0.9700\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yalam\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: Extract features and labels\n",
    "X = df['processed_comment']  # Features (text-based)\n",
    "y = df[['Technology', 'Technology in Education', 'Technology in Workforce Development']]  # Multi-output target\n",
    "\n",
    "# Preprocess text data using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # Adjust max_features as needed\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Handling class imbalance using SMOTE (for each target column)\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Define models to try\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, random_state=42),\n",
    "}\n",
    "\n",
    "# Hyperparameter search spaces for each model\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': uniform(0.1, 10),\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "        'C': uniform(0.1, 10),\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_name, model, param_grid, y_column):\n",
    "    # Hyperparameter tuning with RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, cv=3, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    # Fit the model\n",
    "    random_search.fit(X_train, y_train[y_column])\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluation Metrics\n",
    "    \n",
    "    accuracy = accuracy_score(y_test[y_column], y_pred)\n",
    "    macro_precision = precision_score(y_test[y_column], y_pred, average='macro')\n",
    "    macro_recall = recall_score(y_test[y_column], y_pred, average='macro') \n",
    "    micro_precision = precision_score(y_test[y_column], y_pred, average='micro')\n",
    "    micro_recall = recall_score(y_test[y_column], y_pred, average='micro') \n",
    "    # Compute Macro and Micro F1 scores\n",
    "    macro_f1 = f1_score(y_test[y_column], y_pred, average='macro')\n",
    "    micro_f1 = f1_score(y_test[y_column], y_pred, average='micro')\n",
    "    \n",
    "    print(f\"{model_name} for {y_column} Classification Metrics:\")\n",
    "    print(f\"  accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"  macro_precision:   {macro_precision:.4f}\")\n",
    "    print(f\"  macro_recall:   {macro_recall:.4f}\")\n",
    " \n",
    "    print(f\"  micro_precision:   {micro_precision:.4f}\")\n",
    "    print(f\"  micro_recall:   {micro_recall:.4f}\")\n",
    "    print(f\"  Macro F1:    {macro_f1:.4f}\")\n",
    "    print(f\"  Micro F1:    {micro_f1:.4f}\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Evaluate for each target column\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\\n\")\n",
    "    for target_column in y.columns:\n",
    "        train_and_evaluate_model(model_name, model, param_grids[model_name], target_column)\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5f328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
